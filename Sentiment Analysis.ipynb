{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('/Users/colette/Documents/GitHub/data_science/sentiment labelled sentences/imdb_labelled.txt', sep=\"\\t\", header=None)\n",
    "df.columns = [\"review\", \"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column review are: 745\n",
      "Unique values in column rating are: 2\n"
     ]
    }
   ],
   "source": [
    "for column_name in df.columns:\n",
    "    print(\"Unique values in column {} are: {}\".format(column_name, df[column_name].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 2 columns):\n",
      "review    748 non-null object\n",
      "rating    748 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  A very, very, very slow-moving, aimless movie ...       0\n",
       "1  Not sure who was more lost - the flat characte...       0\n",
       "2  Attempting artiness with black & white and cle...       0\n",
       "3       Very little music or anything to speak of.         0\n",
       "4  The best scene in the movie was when Gerardo i...       1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    748\n",
       "rating    748\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no missing values\n",
    "df.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MOIST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-458225ff6509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mclean_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "#parse words for review into positive and negative list\n",
    "all_words = []\n",
    "\n",
    "for i, j in df.iterrows():\n",
    "    text = df['review'][i]\n",
    "    text.lower() # Convert to lowercase\n",
    "    words = re.findall(\"[a-z0-9']+\", text) # extract the words\n",
    "    all_words = all_words + words\n",
    "    \n",
    "sr= stopwords.words('english')\n",
    "clean_tokens = all_words[:]\n",
    "for word in all_words:\n",
    "    if word in stopwords.words('english'):\n",
    "        clean_tokens.remove(word)\n",
    "freq = nltk.FreqDist(clean_tokens)\n",
    "for key,val in freq.items():\n",
    "    print(str(key) + ':' + str(val))\n",
    "freq.plot(20, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1\n",
    "\n",
    "Using only negative keywords and BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_keywords = ['bad', 'slow', 'ridiculous', 'poor', 'little', 'empt', 'predictable', 'crap'\n",
    "                , 'mediocre', 'worst', 'annoy', 'bore', 'boring', 'stereotypical', 'worse', 'suck'\n",
    "                , 'fail', 'cheap', 'trash', 'lack', 'mess', 'unconvinc']\n",
    "\n",
    "for key in neg_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    df[str(key)] = df['review'].str.contains(str(key), case=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[neg_keywords]\n",
    "target = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('percentage wrong = {}'.format(round(243/748*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2\n",
    "\n",
    "Using postiive keywords to see if accuracy is improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_keywords = ['clever', 'best', 'ador', 'appeal', 'perfect', 'beautiful', 'love', 'enjoy', 'funny', 'believ'\n",
    "                ,'terrific', 'excel', 'incredible', 'fascinate', 'solid', 'hope', 'wonder', 'master', 'intelligent'\n",
    "                , 'entertain', 'memorable', 'brillian', 'special', 'top']\n",
    "\n",
    "for key in pos_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    df[str(key)] = df['review'].str.contains(str(key), case=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[pos_keywords]\n",
    "target = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('percentage wrong = {}'.format(round(243/748*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('sensitivy = {}'.format(round(132/(132+254), 2)))\n",
    "print ('specificity = {}'.format(round(346/(346+16), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3\n",
    "\n",
    "Failed attempt at using both positve AND negative keywords with multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_keywords = ['bad', 'slow', 'ridiculous', 'poor', 'little', 'empt', 'predictable', 'crap'\n",
    "                , 'mediocre', 'worst', 'annoy', 'bore', 'boring', 'stereotypical', 'worse', 'suck'\n",
    "                , 'fail', 'cheap', 'trash', 'lack', 'mess', 'unconvinc']\n",
    "\n",
    "pos_keywords = ['clever', 'best', 'ador', 'appeal', 'perfect', 'beautiful', 'love', 'enjoy', 'funny', 'believ'\n",
    "                ,'terrific', 'excel', 'incredible', 'fascinate', 'solid', 'hope', 'wonder', 'master', 'intelligent'\n",
    "                , 'entertain', 'memorable', 'brillian', 'special', 'top']\n",
    "\n",
    "for key in neg_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    df[str(key)] = df['review'].str.contains(str(key), case=0)\n",
    "    \n",
    "for key in pos_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    df[str(key)] = df['review'].str.contains(str(key), case=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(['review'], axis=1)\n",
    "\n",
    "drop_idxs = []\n",
    "\n",
    "for idx in df_new.index:\n",
    "    if not df_new.loc[idx,:].tolist():\n",
    "        drop_idxs.append(idx)\n",
    "df_new = df_new.drop(drop_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = []\n",
    "\n",
    "for index in df_new.index:\n",
    "#    if df_new.loc[index, 'rating'] == 1:\n",
    " #       if df_new.loc[index, neg_keywords].tolist():\n",
    "  #          drop_index.append(index)\n",
    "    if df_new.loc[index, 'rating'] == 0:\n",
    "        if df_new.loc[index, pos_keywords].tolist():\n",
    "            drop_index.append(index)        \n",
    "        \n",
    "    \n",
    "#df_new = df_new.drop(drop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(drop_index[:len(drop_index)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 374 entries, 321 to 747\n",
      "Data columns (total 47 columns):\n",
      "rating           374 non-null int64\n",
      "bad              374 non-null bool\n",
      "slow             374 non-null bool\n",
      "ridiculous       374 non-null bool\n",
      "poor             374 non-null bool\n",
      "little           374 non-null bool\n",
      "empt             374 non-null bool\n",
      "predictable      374 non-null bool\n",
      "crap             374 non-null bool\n",
      "mediocre         374 non-null bool\n",
      "worst            374 non-null bool\n",
      "annoy            374 non-null bool\n",
      "bore             374 non-null bool\n",
      "boring           374 non-null bool\n",
      "stereotypical    374 non-null bool\n",
      "worse            374 non-null bool\n",
      "suck             374 non-null bool\n",
      "fail             374 non-null bool\n",
      "cheap            374 non-null bool\n",
      "trash            374 non-null bool\n",
      "lack             374 non-null bool\n",
      "mess             374 non-null bool\n",
      "unconvinc        374 non-null bool\n",
      "clever           374 non-null bool\n",
      "best             374 non-null bool\n",
      "ador             374 non-null bool\n",
      "appeal           374 non-null bool\n",
      "perfect          374 non-null bool\n",
      "beautiful        374 non-null bool\n",
      "love             374 non-null bool\n",
      "enjoy            374 non-null bool\n",
      "funny            374 non-null bool\n",
      "believ           374 non-null bool\n",
      "terrific         374 non-null bool\n",
      "excel            374 non-null bool\n",
      "incredible       374 non-null bool\n",
      "fascinate        374 non-null bool\n",
      "solid            374 non-null bool\n",
      "hope             374 non-null bool\n",
      "wonder           374 non-null bool\n",
      "master           374 non-null bool\n",
      "intelligent      374 non-null bool\n",
      "entertain        374 non-null bool\n",
      "memorable        374 non-null bool\n",
      "brillian         374 non-null bool\n",
      "special          374 non-null bool\n",
      "top              374 non-null bool\n",
      "dtypes: bool(46), int64(1)\n",
      "memory usage: 22.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 374 points : 114\n"
     ]
    }
   ],
   "source": [
    "data = df_new.drop(['rating'], axis=1)\n",
    "target = df_new['rating']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage wrong = 23.1\n"
     ]
    }
   ],
   "source": [
    "print ('percentage wrong = {}'.format(round(131/567*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.7807017543859649\n",
      "Testing on Sample: 0.7689594356261023\n"
     ]
    }
   ],
   "source": [
    "# Test your model with different holdout groups.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61538462, 0.52631579, 0.65789474, 0.54054054, 0.64864865,\n",
       "       0.62162162, 0.59459459, 0.62162162, 0.72972973, 0.72972973])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
